{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)\n",
    "#importing BeautifulSoup from bs4 package\n",
    "from bs4 import BeautifulSoup \n",
    "#importing requests package\n",
    "import requests \n",
    "#assigning the url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "#getting the url response \n",
    "r = requests.get(url) \n",
    "\n",
    "#converting the response into text format\n",
    "html_doc = r.text \n",
    "\n",
    "#parsing through the html_doc using beautifulsoup\n",
    "soup = BeautifulSoup(html_doc,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(2)\n",
    "# Count the number of hyperlink URLs (which begin with http) in the <u>head</u> & <u>body</u> tags\n",
    "#creating seperate bs4 element tags for head and body\n",
    "hd = soup.head\n",
    "bd = soup.body\n",
    "\n",
    "#number of links is equal to the sum of links in head tag and body tag\n",
    "nlinks = len(hd.find_all('a'))+len(bd.find_all('a'))\n",
    "nlinks #25 zero in head + 25 in body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3a):  Generate a unique list of hyperlink URLs (which begin with http) from the <u>body</u> tag and convert it into a pandas <u>series</u> object.\\n\",\n",
    "#\"- If your website body has no hyperlinks, please select a new website and repeat question.\n",
    "\n",
    "#finding all the a tags and its content and holding them in a bs.element.result:\n",
    "a_rslt = bd.find_all('a')\n",
    "#importing pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "#Converting list into pandas series\n",
    "a_series = pd.Series(a_rslt)\n",
    "\n",
    "#coverting series into list using tolist() method\n",
    "a_list = a_series.tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3b):  Create a function which parses the domain name (parent website) from a hyperlink URL\n",
    "#function that takes a string as input and splits it into difeerent parts as specified by start and end in split function and returns the selected output\n",
    "def url(s):\n",
    "    s=str(s)\n",
    "    domain = s.split(\"//\")[-1].split(\"/\")[0]\n",
    "    return domain\n",
    "\n",
    "#passing all the values in a_list to the function\n",
    "a_domain = [url(d) for d in a_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ( 3c ): Create a new pandas series composed of domain names.\\n\",\n",
    "#    \"- Consider using the <b>series.map()</b> method, applying your function from (3b) over the series in (3a)\\n\",\n",
    "\n",
    "f = a_series.map(url, na_action=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ( 4a ) Choose an RSS feed site and retrieve the XML data using urllib.\\n\",\n",
    " #   \"- If it doesnâ€™t return a page (perhaps because it uses cookies or other interactions to actually return content), try a different site.\\n\",\n",
    " #   \"- Here is a list of RSS Feeds to get you started:\\n\",\n",
    " #   \"    - <b>https://rss.com/popular-rss-feeds/</b>\\n\",\n",
    " #   \"\\n\",\n",
    " #   \"#### ( 4b ) Use ElementTree to parse the object (like we did in class).\\n\",\n",
    "    \n",
    "import xml.etree.ElementTree as ET \n",
    "#url = 'https://www.omnycontent.com/d/playlist/4b5f9d6d-9214-48cb-8455-a73200038129/a7c446d6-29da-43ba-bbe5-a7da00ecda4a/a65603a6-cf22-4150-91c1-a7da00ed5220/podcast.rss'\n",
    "#url ='http://podcastfeeds.nbcnews.com/drone/api/query/audio/podcast/1.0/MSNBC-MTP.xml'\n",
    "#url = 'http://www.hindustantimes.com/rss/topnews/rssfeed.xml'\n",
    "url = 'https://feeds.a.dj.com/rss/RSSWorldNews.xml'\n",
    "#url = 'https://www.w3schools.com/xml/xml_rss.asp'\n",
    "#url = 'https://www.themoviedb.org/movie'\n",
    "import requests\n",
    "x = requests.get(url)\n",
    "\n",
    "doc = x.text\n",
    "with open('topnewsfeed.xml', 'wb') as f: \n",
    "    f.write(x.content) \n",
    "from bs4 import BeautifulSoup \n",
    "soup = BeautifulSoup(doc,'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = r'C:\\Users\\KARTHEEK SP\\Desktop\\topnewsfeed.xml'\n",
    "# out = open(filepath, 'w')\n",
    "# out.write(xmlstring)\n",
    "tree = ET.parse('topnewsfeed.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is only 1 parent tag by definition\n",
      "There are 7 child tags\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ( 5 ): Count the number of Top-level <u>parent tags</u> & their number of <u>child</u> tags.\\n\",\n",
    "   # \"- Top-level means that a tag has <b><u>no</b></u> parent tag\\n\",\n",
    "   #\"- Only count direct children to these top level tags\\n\",\n",
    "firstchild = root[0]\n",
    "itemlist = firstchild.findall('item')\n",
    "print(\"There is only\", str(len(root)), \"parent tag by definition\")\n",
    "print(\"There are\", str(len(itemlist)), \"child tags\")\n",
    "len(itemlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Title', 'Link', 'Description', 'Publishing Date', 'GUID', 'Category']\n",
      "                                               Title  \\\n",
      "0                                WSJ.com: World News   \n",
      "1                                WSJ.com: World News   \n",
      "2    Turkey Elections Loosen Erdogan's Grip on Power   \n",
      "3  Facebook Removes Hundreds of Fake Accounts Ahe...   \n",
      "4  Singapore Fake-News Bill Orders Corrections by...   \n",
      "\n",
      "                                                Link  \\\n",
      "0             http://online.wsj.com/page/2_0006.html   \n",
      "1             http://online.wsj.com/page/2_0006.html   \n",
      "2  https://www.wsj.com/articles/erdogans-grip-on-...   \n",
      "3  https://www.wsj.com/articles/facebook-removes-...   \n",
      "4  https://www.wsj.com/articles/singapore-fake-ne...   \n",
      "\n",
      "                                         Description  \\\n",
      "0                                               None   \n",
      "1                                         World News   \n",
      "2  The party of President Recep Tayyip Erdogan ap...   \n",
      "3  Facebook said it has taken down hundreds of pa...   \n",
      "4  Tech giants such as Facebook, Google and Twitt...   \n",
      "\n",
      "                   Publishing Date  \\\n",
      "0                             None   \n",
      "1  Mon, 01 Apr 2019 17:25:55 -0400   \n",
      "2  Mon, 01 Apr 2019 16:52:00 -0400   \n",
      "3  Mon, 01 Apr 2019 11:18:00 -0400   \n",
      "4  Mon, 01 Apr 2019 10:40:00 -0400   \n",
      "\n",
      "                                          GUID Category  \n",
      "0                                         None     None  \n",
      "1                                         None     None  \n",
      "2  SB11709494519906504674704585215883512906228     PAID  \n",
      "3  SB12662870982563384866504585216340060827352     PAID  \n",
      "4  SB12662870982563384866504585216211612564810     PAID  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>Description</th>\n",
       "      <th>Publishing Date</th>\n",
       "      <th>GUID</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>WSJ.com: World News</td>\n",
       "      <td>http://online.wsj.com/page/2_0006.html</td>\n",
       "      <td>A wider range of fentanyl derivatives will be ...</td>\n",
       "      <td>Sun, 31 Mar 2019 19:09:00 -0400</td>\n",
       "      <td>SB11709494519906504674704585215883512906228</td>\n",
       "      <td>PAID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Title                                    Link  \\\n",
       "count                     9                                       9   \n",
       "unique                    8                                       8   \n",
       "top     WSJ.com: World News  http://online.wsj.com/page/2_0006.html   \n",
       "freq                      2                                       2   \n",
       "\n",
       "                                              Description  \\\n",
       "count                                                   8   \n",
       "unique                                                  8   \n",
       "top     A wider range of fentanyl derivatives will be ...   \n",
       "freq                                                    1   \n",
       "\n",
       "                        Publishing Date  \\\n",
       "count                                 8   \n",
       "unique                                8   \n",
       "top     Sun, 31 Mar 2019 19:09:00 -0400   \n",
       "freq                                  1   \n",
       "\n",
       "                                               GUID Category  \n",
       "count                                             7        7  \n",
       "unique                                            7        1  \n",
       "top     SB11709494519906504674704585215883512906228     PAID  \n",
       "freq                                              1        7  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # ( 6a ): Convert all of the items of your RSS XML into a pandas dataframe.\\n\",\n",
    "#     \"- An item in an RSS feed begins with an item tag < item > ... < /item >\\n\",\n",
    "#     \"- Each row represents 1 item\\n\",\n",
    "#     \"- Each column represents 1 child-tag to the parent <u>item</u> tag:\\n\",\n",
    "#     \"    - i.e.: Title, Link, PubDate, Category\\n\",\n",
    "#     \"        - Ignore children of these tags\\n\",\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "firstitem = firstchild.find('item')\n",
    "alltitles = tree.findall('.//title')\n",
    "alllinks = tree.findall('.//link')\n",
    "alldescription = tree.findall('.//description')\n",
    "allpubdate = tree.findall('.//pubDate')\n",
    "allguid = tree.findall('.//guid')\n",
    "allcategory = tree.findall('.//category')\n",
    "\n",
    "dfcols = ['Title', 'Link', 'Description', 'Publishing Date', 'GUID', \"Category\"]\n",
    "\n",
    "titles = [x.text for x in alltitles] # has the largest list, but the array must be equal in length 19\n",
    "links = [x.text for x in alllinks] #19\n",
    "description = [x.text for x in alldescription] #18\n",
    "pubdate = [x.text for x in allpubdate] #18\n",
    "guid = [x.text for x in allguid] #17\n",
    "category = [x.text for x in allcategory] #17\n",
    "\n",
    "#adjust the list to match the array values\n",
    "for values in range(1):\n",
    "    description.insert(values, None)\n",
    "    pubdate.insert(values, None)\n",
    "\n",
    "#adjust to match the array value \n",
    "for values in range(2):\n",
    "    guid.insert(values, None)\n",
    "    category.insert(values, None)\n",
    "\n",
    "\n",
    "dfdata = {'Title': titles, 'Link': links, 'Description': description, 'Publishing Date': pubdate, 'GUID': guid, \"Category\": category}\n",
    "print(dfcols)\n",
    "\n",
    "xml_df = pd.DataFrame.from_dict(dfdata)\n",
    "print(xml_df.head())\n",
    "\n",
    "#6b .describe()\n",
    "# I think this is it\n",
    "xml_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
